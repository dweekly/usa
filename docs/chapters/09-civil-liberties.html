<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="CHAPTER IX — CIVIL LIBERTIES & DIGITAL RIGHTS - United States of Awesome">
    <title>CHAPTER IX — CIVIL LIBERTIES & DIGITAL RIGHTS | United States of Awesome</title>
    <link rel="stylesheet" href="chapter-style.css">
</head>
<body>
    <div class="container">
        <header>
            <a href="../index.html"><img src="../assets/logotext-800.png" alt="United States of Awesome" class="logo"></a>
            <div class="breadcrumb">
                <a href="../index.html">Home</a> → CHAPTER IX — CIVIL LIBERTIES & DIGITAL RIGHTS
            </div>
        </header>
        <main>
<h1 id="chapter-ix-civil-liberties-digital-rights"><strong>CHAPTER IX —
CIVIL LIBERTIES &amp; DIGITAL RIGHTS</strong></h1>
<p><em>Freedom as the Operating System of the United States of
Awesome</em></p>
<h2 id="introduction"><strong>Introduction</strong></h2>
<p>Civil liberties are the backbone of the American experiment. They are
not relics; they are the architecture that allows:</p>
<ul>
<li>Social trust</li>
<li>Creativity</li>
<li>Entrepreneurship</li>
<li>Dissent</li>
<li>Individual dignity</li>
<li>Technological progress</li>
<li>Democratic legitimacy</li>
</ul>
<p>But 21st-century technologies—AI, ubiquitous sensors, cloud
platforms, digital intermediaries—are reshaping the landscape so
profoundly that <strong>old rules no longer protect freedom by
default</strong>.</p>
<p>We need a modern Bill of Rights for the digital age—one that:</p>
<ul>
<li>Guards freedom of expression</li>
<li>Protects privacy</li>
<li>Limits state and corporate surveillance</li>
<li>Ensures accountability</li>
<li>Keeps encryption strong</li>
<li>Defines proper use of AI</li>
<li>Maintains lawful access standards</li>
<li>Prevents de facto censorship</li>
<li>Preserves the autonomy of individuals</li>
<li>Allows safe innovation</li>
<li>Protects children</li>
<li>Respects adult agency</li>
<li>Limits coercive power</li>
<li>Strengthens democracy</li>
</ul>
<p>In short:</p>
<blockquote>
<p><strong>We must reinterpret and reinforce the American commitment to
liberty for a world where every citizen interacts through digital
intermediaries.</strong></p>
</blockquote>
<p>This chapter lays out the framework.</p>
<h1 id="freedom-as-default-in-the-21st-century"><strong>1. Freedom as
Default in the 21st Century</strong></h1>
<h2 id="freedom-is-the-engine-of-american-strength"><strong>1.1 Freedom
Is the Engine of American Strength</strong></h2>
<p>Freedom is not merely noble—it is instrumentally useful:</p>
<ul>
<li>Free societies innovate faster</li>
<li>Free researchers make better science</li>
<li>Free media uncovers corruption</li>
<li>Free workers negotiate better</li>
<li>Free thinkers challenge orthodoxy</li>
<li>Free speech creates resilience</li>
</ul>
<p>Authoritarian regimes can build infrastructure quickly, but they
cannot <strong>imagine</strong> the future. Only free people do
that.</p>
<h2 id="freedom-requires-guardrails-against-power"><strong>1.2 Freedom
Requires Guardrails Against Power</strong></h2>
<p>Power accumulates in three vectors:</p>
<ul>
<li><strong>Government</strong></li>
<li><strong>Corporations</strong></li>
<li><strong>Algorithms</strong></li>
</ul>
<p>Each can suppress or distort freedom:</p>
<ul>
<li>Through surveillance</li>
<li>Through manipulation</li>
<li>Through silent censorship</li>
<li>Through data capture</li>
<li>Through algorithmic discrimination</li>
</ul>
<p>We propose a framework that protects citizens from <em>all
three</em>.</p>
<h1 id="free-speech-in-the-digital-age"><strong>2. Free Speech in the
Digital Age</strong></h1>
<h2 id="classical-constitutional-doctrine-still-holds"><strong>2.1
Classical Constitutional Doctrine Still Holds</strong></h2>
<p>The First Amendment protects:</p>
<ul>
<li>Political speech</li>
<li>Religious speech</li>
<li>Controversial speech</li>
<li>Unpopular speech</li>
<li>Offensive speech</li>
<li>Artistic expression</li>
<li>Scientific discourse</li>
</ul>
<p>The state may regulate:</p>
<ul>
<li>True threats</li>
<li>Incitement to imminent lawless action</li>
<li>Fraud</li>
<li>Defamation</li>
<li>Harassment</li>
<li>Explicitly unlawful conduct</li>
</ul>
<p>But the default is freedom—<em>not</em> government preference or
“consensus policing.”</p>
<h2 id="the-modern-threat-governmentplatform-backchannels"><strong>2.2
The Modern Threat: Government–Platform Backchannels</strong></h2>
<p>The danger is not explicit censorship—it is informal pressure.</p>
<p>A world where:</p>
<ul>
<li>Government agencies “request” takedowns</li>
<li>Platforms comply out of fear</li>
<li>Users never see the interference</li>
<li>Algorithms invisibly suppress viewpoints</li>
</ul>
<p>…is incompatible with free society.</p>
<p>We propose:</p>
<blockquote>
<p><strong>Mandatory transparency for all government–platform
communications affecting user content.</strong></p>
</blockquote>
<p>This includes:</p>
<ul>
<li>Logging</li>
<li>Public reporting</li>
<li>Judicial review pathways</li>
<li>Congressional oversight</li>
</ul>
<p>No secret persuasion. No shadow censorship.</p>
<h2 id="platform-governance-without-state-coercion"><strong>2.3 Platform
Governance Without State Coercion</strong></h2>
<p>Private platforms have rights: They can moderate according to their
values.</p>
<p>But when government actors influence moderation:</p>
<ul>
<li>They must be transparent</li>
<li>They must be limited</li>
<li>They must be accountable</li>
</ul>
<p>Platforms should publish:</p>
<ul>
<li>Algorithmic ranking changes</li>
<li>Moderation guidelines</li>
<li>Government removal requests</li>
<li>Data on enforcement equity</li>
</ul>
<p>This builds trust and preserves autonomy.</p>
<h2 id="disinformation-governance-must-be-evidence-based"><strong>2.4
“Disinformation” Governance Must Be Evidence-Based</strong></h2>
<p>The term “disinformation” has become politicized. The solution is not
to suppress speech. The solution is to <strong>strengthen critical
reasoning</strong> (Chapter V).</p>
<p>A free nation counters bad ideas with:</p>
<ul>
<li>Better ideas</li>
<li>Clear evidence</li>
<li>Education</li>
<li>Transparency</li>
</ul>
<p>Not with suppression.</p>
<h1 id="encryption-privacy-the-modern-fourth-amendment"><strong>3.
Encryption &amp; Privacy: The Modern Fourth Amendment</strong></h1>
<h2 id="strong-encryption-is-non-negotiable"><strong>3.1 Strong
Encryption Is Non-Negotiable</strong></h2>
<p>Any backdoor, key escrow mechanism, or “exceptional access”
mandate:</p>
<ul>
<li>Weakens security for everyone</li>
<li>Empowers criminals, hostile nations, and abusive actors</li>
<li>Cannot be limited to “good guys”</li>
<li>Violates constitutional protections</li>
<li>Makes future authoritarian drift far more dangerous</li>
</ul>
<p>We propose:</p>
<blockquote>
<p><strong>A federal guarantee that citizens may use unbreakable
end-to-end encryption.</strong></p>
</blockquote>
<p>Not because we want to shield criminals— but because weakening
encryption makes <em>everyone</em> a target.</p>
<h2 id="cloud-data-demands-constitutional-protection"><strong>3.2 Cloud
Data Demands Constitutional Protection</strong></h2>
<p>The Fourth Amendment was written for a world of physical papers.
Today:</p>
<ul>
<li>Personal correspondence lives in cloud servers</li>
<li>Location data is constantly generated</li>
<li>Search queries reveal intimate thoughts</li>
<li>Contact graphs expose social networks</li>
<li>Photos, videos, health data, and financials all flow through digital
intermediaries</li>
</ul>
<p>We propose:</p>
<blockquote>
<p><strong>Digital data deserves the same protections as papers and
effects.</strong></p>
<p>This means:</p>
<ul>
<li>Warrant requirements</li>
<li>Particularity standards</li>
<li>Judicial oversight</li>
<li>Limits on bulk collection</li>
<li>Clear deletion timelines</li>
</ul>
</blockquote>
<h2
id="no-mass-surveillance-without-narrow-legislated-mandates"><strong>3.3
No Mass Surveillance Without Narrow, Legislated Mandates</strong></h2>
<p>We reject:</p>
<ul>
<li>Warrantless metadata dragnet programs</li>
<li>Bulk data buys from private brokers</li>
<li>Continuous automated license plate scanning databases</li>
<li>Unconstrained use of facial recognition</li>
</ul>
<p>Instead:</p>
<ul>
<li>Specific warrants</li>
<li>Public audits</li>
<li>Narrow usage cases</li>
<li>Opt-in community surveillance (e.g., business districts) only under
strict rules</li>
<li>Face recognition only for serious crimes with judicial review</li>
</ul>
<h1 id="ai-governance-and-algorithmic-accountability"><strong>4. AI
Governance and Algorithmic Accountability</strong></h1>
<h2 id="ai-as-a-freedom-enablerand-risk"><strong>4.1 AI as a Freedom
Enabler—and Risk</strong></h2>
<p>AI can:</p>
<ul>
<li>Democratize tutoring</li>
<li>Accelerate research</li>
<li>Reduce bureaucracy</li>
<li>Enhance productivity</li>
</ul>
<p>But it can also:</p>
<ul>
<li>Amplify bias</li>
<li>Enable surveillance</li>
<li>Manipulate attention</li>
<li>Produce synthetic propaganda</li>
<li>Create chilling effects</li>
</ul>
<p>We must govern AI with <strong>civil liberties at the core</strong>,
not as an afterthought.</p>
<h2 id="principles-for-ai-governance"><strong>4.2 Principles for AI
Governance</strong></h2>
<p>We propose:</p>
<h3 id="human-accountability-for-consequential-decisions"><strong>1.
Human accountability for consequential decisions</strong></h3>
<p>No algorithm gets to decide:</p>
<ul>
<li>Arrest</li>
<li>Detention</li>
<li>Sentencing</li>
<li>Welfare benefits</li>
<li>Medical eligibility</li>
<li>Immigration status</li>
<li>School placement</li>
</ul>
<h3 id="transparency-where-algorithms-affect-rights"><strong>2.
Transparency where algorithms affect rights</strong></h3>
<p>People deserve to know:</p>
<ul>
<li>When AI is used</li>
<li>What factors influence decisions</li>
<li>How to challenge results</li>
</ul>
<h3 id="no-predictive-policing-based-on-protected-classes"><strong>3. No
predictive policing based on protected classes</strong></h3>
<p>Data must be:</p>
<ul>
<li>Fair</li>
<li>Auditable</li>
<li>Context-aware</li>
</ul>
<h3 id="right-to-human-review"><strong>4. Right to human
review</strong></h3>
<p>If an algorithm affects someone’s rights, a human must review upon
request.</p>
<h2 id="algorithmic-discrimination-audits"><strong>4.3 Algorithmic
Discrimination Audits</strong></h2>
<p>Platforms and agencies must run regular audits to check for:</p>
<ul>
<li>Racial bias</li>
<li>Gender bias</li>
<li>Disability discrimination</li>
<li>False positives/negatives</li>
<li>Geographic disparities</li>
</ul>
<p>Results must be made public.</p>
<p>— a/chapters/09-civil-liberties.md +++
b/chapters/09-civil-liberties.md @@ -305,6 +305,64 @@ Platforms and
agencies must run regular audits to check for:</p>
<ul>
<li>Racial bias</li>
<li>Gender bias</li>
<li>Disability discrimination</li>
<li>False positives/negatives</li>
<li>Geographic disparities</li>
</ul>
<p>Results must be made public.</p>
<h2 id="ai-assisted-democracy-and-personal-policy-twins"><strong>4.4
AI-Assisted Democracy and Personal Policy Twins</strong></h2>
<p>AI does not have voting rights and must never become a new class of
voter. But it can help humans participate more often and more
thoughtfully in the decisions that affect them.</p>
<p>The United States of Awesome supports careful experiments with
<strong>“personal policy twins”</strong>: AI systems that learn an
individual’s values and preferences and can <em>advise</em> or
<em>proxy-vote</em> for them in purely voluntary, revocable ways.</p>
<p>We adopt four core principles:</p>
<ol type="1">
<li><strong>Human agency first</strong>
<ul>
<li>Every eligible person has one vote.</li>
<li>A person may delegate to a policy twin, but may override any
recommendation or cast their own vote at any time.</li>
<li>If “better-informed me” and “current me” disagree, current me wins.
Anything else would quietly disenfranchise real people in favor of
algorithms.</li>
</ul></li>
<li><strong>User choice and model plurality</strong>
<ul>
<li>Citizens choose which model represents them—public, commercial,
open-source, or self-hosted at home.</li>
<li>The system must support <strong>data portability</strong> so people
can move their civic profile and configuration between models at
will.</li>
<li>Independent audits should stress-test models used for civic purposes
for obvious misbehavior (fabricated evidence, persistent bias, ignoring
user settings), while leaving room for ideological diversity.</li>
</ul></li>
<li><strong>Private logs and explainability</strong>
<ul>
<li>Each person can see how their policy twin acted on their behalf and
<em>why</em>—what sources it consulted, how it weighed tradeoffs, and
how it interpreted their stated values.</li>
<li>By default, this log is <strong>private</strong>, protected like
health or financial records. No employer, party, or agency should be
able to compel access to an individual’s voting history or twin
rationale.</li>
<li>People should be able to tune their twin, including choosing whether
it should mirror “current me” or approximate a “better-informed me” that
has read more deeply and consulted more sources before taking a
position.</li>
</ul></li>
<li><strong>Advisory first, democracy always in the loop</strong>
<ul>
<li>Early deployments should be <strong>advisory</strong>, not binding:
personal policy twins and aggregated “constituent dashboards” help
representatives and parties understand what people would likely think if
they had more time and information.</li>
<li>Any move toward binding, automated voting must follow years of
experimentation, public debate, and legal safeguards, and still preserve
the core rule that humans remain the ultimate source of democratic
authority.</li>
</ul></li>
</ol>
<p>Non-participation remains a protected choice:</p>
<ul>
<li>People who decline to vote or delegate simply are not counted; the
system must not invent “ghost votes” for them.</li>
<li>We may use statistical models to simulate how non-participants
<em>might</em> have voted as a diagnostic tool—for example, to highlight
whose voices are missing—but simulated citizens are not citizens, and
their ghost votes must never be counted as real.</li>
</ul>
<p>Finally, we recognize that AI policy twins raise deep equity
questions:</p>
<ul>
<li>Wealthy, time-rich people will often have better-tuned agents.</li>
<li>To prevent AI-assisted democracy from becoming “power tools for the
already-powerful,” we support publicly funded, high-quality baseline
twins that are free to every citizen, with special attention to
low-income, low-literacy, and low-connectivity communities.</li>
</ul>
<p>This chapter focuses on the civil-liberties guardrails for such
systems. Separate chapters on democracy and electoral infrastructure
will define <em>when and how</em> AI-assisted participation should
inform actual election procedures.</p>
<hr />
<p># <strong>5. Protecting Children Without Trampling
Rights</strong></p>
<h1 id="protecting-children-without-trampling-rights"><strong>5.
Protecting Children Without Trampling Rights</strong></h1>
<h2 id="the-challenge"><strong>5.1 The Challenge</strong></h2>
<p>Children face:</p>
<ul>
<li>Predators</li>
<li>Bullying</li>
<li>Exploitation</li>
<li>Algorithmic manipulation</li>
<li>Inappropriate content</li>
<li>Mental health stressors</li>
<li>Sextortion</li>
<li>Online radicalization</li>
<li>Screen addiction</li>
</ul>
<p>But heavy-handed restrictions:</p>
<ul>
<li>Hurt LGBTQ+ youth</li>
<li>Silence vulnerable teens</li>
<li>Violate privacy</li>
<li>Reduce autonomy</li>
<li>Create dangerous precedent</li>
<li>Ignore underlying mental health drivers</li>
</ul>
<p>We need balanced, non-ideological measures.</p>
<h2 id="solutions"><strong>5.2 Solutions</strong></h2>
<h3 id="safe-accounts-for-minors"><strong>1. Safe Accounts for
Minors</strong></h3>
<ul>
<li>Enhanced default privacy</li>
<li>Restrictions on unsolicited messages</li>
<li>Transparent content filtering</li>
<li>Parental dashboards (with teen input)</li>
</ul>
<h3 id="education-not-censorship"><strong>2. Education, Not
Censorship</strong></h3>
<ul>
<li>Digital literacy taught in middle school</li>
<li>Training for parents</li>
<li>AI-driven moderation tools that protect rights</li>
</ul>
<h3 id="law-enforcement-against-abusers"><strong>3. Law Enforcement
Against Abusers</strong></h3>
<ul>
<li>Increase funding for ICAC (Internet Crimes Against Children)</li>
<li>Prioritize prosecution of predators, not teens</li>
<li>International cooperation</li>
</ul>
<h3 id="algorithms-that-dont-prey-on-kids"><strong>4. Algorithms That
Don’t Prey on Kids</strong></h3>
<ul>
<li>Ban algorithmic amplification of harmful content to minors</li>
<li>Enforce daily screen-time limits on addictive recommendation loops
(opt-in for adults; default for minors)</li>
<li>Strict oversight for teen-targeted ads</li>
</ul>
<h1
id="restraining-state-power-limits-on-intelligence-law-enforcement"><strong>6.
Restraining State Power: Limits on Intelligence &amp; Law
Enforcement</strong></h1>
<h2 id="guardrails"><strong>6.1 Guardrails</strong></h2>
<p>We propose:</p>
<ul>
<li>Clear statutory limits on intelligence agency data access</li>
<li>Independent oversight boards with civil liberties
representation</li>
<li>Strengthened whistleblower protections</li>
<li>Limits on parallel construction</li>
<li>Transparency reports</li>
<li>Congressional renewal requirements for surveillance powers</li>
<li>Ban on purchasing location data from data brokers without
warrants</li>
</ul>
<h2 id="lawful-hacking-only-under-warrant"><strong>6.2 Lawful Hacking
Only Under Warrant</strong></h2>
<p>Targeted device exploitation is sometimes necessary.</p>
<p>We restrict it to:</p>
<ul>
<li>Serious crimes</li>
<li>Specific devices</li>
<li>With judicial approval</li>
<li>With minimization procedures</li>
</ul>
<p>And require:</p>
<ul>
<li>Post-operation notifications (with exceptions for ongoing
investigations)</li>
<li>Public transparency reports</li>
</ul>
<h1
id="restraining-corporate-power-data-rights-markets-and-choice"><strong>7.
Restraining Corporate Power: Data Rights, Markets, and
Choice</strong></h1>
<h2 id="data-minimization-requirements"><strong>7.1 Data Minimization
Requirements</strong></h2>
<p>Companies must:</p>
<ul>
<li>Collect only necessary data</li>
<li>Delete unused data</li>
<li>Provide export tools</li>
<li>Allow meaningful consent (no dark patterns)</li>
</ul>
<h2 id="privacy-market-signals"><strong>7.2 Privacy Market
Signals</strong></h2>
<ul>
<li>National “Privacy Label” system (modeled after food labels)</li>
<li>Consumer-facing privacy score</li>
<li>Strong penalties for breaches</li>
</ul>
<h2 id="competition-interoperability"><strong>7.3 Competition &amp;
Interoperability</strong></h2>
<ul>
<li>Mandate interoperability for major platforms</li>
<li>Support decentralized identity</li>
<li>Empower competitors without requiring people to give up their social
graphs</li>
</ul>
<h1
id="restraining-algorithmic-censorship-without-mandating-speech"><strong>8.
Restraining Algorithmic Censorship (Without Mandating
Speech)</strong></h1>
<h2 id="platform-rights-user-rights"><strong>8.1 Platform Rights + User
Rights</strong></h2>
<p>We do <strong>not</strong> force platforms to carry specific speech.
But we ensure:</p>
<ul>
<li>Users understand moderation decisions</li>
<li>Appeals processes exist</li>
<li>Algorithmic feeds can be replaced with chronological feeds</li>
<li>Shadow bans are disclosed</li>
<li>Influential accounts have transparency obligations</li>
</ul>
<p>Freedom requires visibility into the “attention economy.”</p>
<h1 id="digital-identity-without-surveillance"><strong>9. Digital
Identity Without Surveillance</strong></h1>
<h2 id="principles"><strong>9.1 Principles</strong></h2>
<p>A modern nation needs:</p>
<ul>
<li>Secure identity</li>
<li>Efficient services</li>
<li>Fraud resistance</li>
</ul>
<p>But digital identity can easily become a surveillance tool.</p>
<p>We propose:</p>
<ul>
<li>Voluntary digital ID</li>
<li>Privacy-preserving cryptographic systems</li>
<li>Zero-knowledge proofs</li>
<li>No centralized tracking</li>
<li>No mandatory usage</li>
<li>No linkage to social scoring or financial privileges</li>
</ul>
<h1 id="critiques-responses"><strong>10. Critiques &amp;
Responses</strong></h1>
<h2 id="from-the-left"><strong>10.1 From the Left</strong></h2>
<p><strong>Critique:</strong> “This gives platforms too much freedom.”
<strong>Response:</strong> Platforms are private entities; coercive
government influence is the greater threat to speech.</p>
<p><strong>Critique:</strong> “Strong encryption makes investigations
harder.” <strong>Response:</strong> Security for everyone requires
encryption that cannot be selectively weakened.</p>
<h2 id="from-the-right"><strong>10.2 From the Right</strong></h2>
<p><strong>Critique:</strong> “Transparency rules pressure platforms to
promote harmful speech.” <strong>Response:</strong> Platforms can still
moderate; they just cannot do so in secret collusion with the state.</p>
<p><strong>Critique:</strong> “Limits on surveillance harm national
security.” <strong>Response:</strong> Broad surveillance is
counterproductive; targeted intelligence is more effective and
constitutionally sound.</p>
<h1 id="metrics-for-success"><strong>11. Metrics for
Success</strong></h1>
<ul>
<li>Reduction in government takedown requests</li>
<li>Increased transparency reporting</li>
<li>No backdoors in encryption</li>
<li>Lower rates of abusive surveillance</li>
<li>Increased trust in institutions</li>
<li>Decline in algorithm-driven harms to minors</li>
<li>Expanded access to privacy-preserving tools</li>
<li>Faster judicial review of digital rights cases</li>
<li>Greater public understanding of digital civic rights</li>
</ul>
<h1 id="implementation-timeline"><strong>12. Implementation
Timeline</strong></h1>
<h3 id="years-12"><strong>Years 1–2</strong></h3>
<ul>
<li>Digital Bill of Rights legislation</li>
<li>Encryption guarantees</li>
<li>Transparency rules</li>
<li>Surveillance reform</li>
<li>Platform communication disclosure laws</li>
<li>Child-safety algorithms deployed</li>
</ul>
<h3 id="years-35"><strong>Years 3–5</strong></h3>
<ul>
<li>AI accountability audits</li>
<li>Data minimization requirements</li>
<li>Interoperability standards</li>
<li>National digital ID (voluntary)</li>
<li>Independent oversight bodies established</li>
</ul>
<h3 id="years-610"><strong>Years 6–10</strong></h3>
<ul>
<li>Major reductions in abusive surveillance</li>
<li>Strong privacy ecosystems</li>
<li>Stable, transparent speech norms</li>
<li>AI systems aligned with civil liberties</li>
<li>Children’s online environments dramatically improved</li>
</ul>
<h1 id="what-success-looks-like-in-20-years"><strong>13. What Success
Looks Like in 20 Years</strong></h1>
<p>By 2045:</p>
<ul>
<li>Americans freely express their views without fear of censorship</li>
<li>Encryption protects ordinary people and critical infrastructure</li>
<li>Government surveillance is targeted, accountable, and
constitutional</li>
<li>Platforms moderate transparently and responsibly</li>
<li>Children are safer online</li>
<li>AI systems amplify human potential without eroding autonomy</li>
<li>The U.S. becomes the global model of digital freedom</li>
<li>Freedom flourishes even in the presence of powerful
technologies</li>
</ul>
<p>A free people must be able to think, speak, learn, build, and dissent
without fear.</p>
<p>This is the civil liberties vision of the <strong>United States of
Awesome</strong>.</p>
        </main>
        <footer>
            <p>
                <strong>This is a living document.</strong>
                <a href="https://github.com/dweekly/usa/blob/main/chapters/09-civil-liberties.md">View source on GitHub</a> •
                <a href="https://github.com/dweekly/usa/issues/new">Provide feedback</a>
            </p>
            <p style="margin-top: 0.5rem;">
                <a href="../index.html">← Back to Home</a>
            </p>
        </footer>
    </div>
</body>
</html>
